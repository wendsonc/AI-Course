# -*- coding: utf-8 -*-
"""KNN - R.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e2pMsIrHksbtwnUsnUkKeYoIMEE-Tuhb

Importar bibliotecas
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import preprocessing
from sklearn import utils
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_regression
from sklearn.neighbors import KNeighborsRegressor

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import confusion_matrix

def adjusted_r2(y_test, y_pred,X_train):
  
  from sklearn.metrics import r2_score

  adj_r2 = (1 - ((1 - r2_score(y_test, y_pred)) * (len(y_test) - 1)) / 
          (len(y_test) - X_train.shape[1] - 1))
    
  return adj_r2

"""Pré-processamento dos dados"""

data = pd.read_csv('winequality-red.csv')
del_atributos = data.drop(['citric acid', 'density', 'pH', 'free sulfur dioxide'], axis=1) #Excluir os atributos 

normalized_geral = MinMaxScaler().fit_transform(del_atributos) #Normalizar toda base de dados

new_data = pd.DataFrame(normalized_geral, columns=['fixed acidity','volatile acidity','residual sugar','chlorides','total sulfur dioxide','sulphates','alcohol','quality']) #Adicionar rotulos 

array_x = np.array(new_data.drop('quality',1))
array_y = np.array(new_data['quality'])

"""Divisão do conjunto de dados em tratamento e teste"""

X = array_x
y = array_y

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=0)

LinearRegressionModel = LinearRegression()
LinearRegressionModel.fit(X_train,y_train)
y_pred = LinearRegressionModel.predict(X_test)

"""Aplicação do KNN com a metríca de similaridade BALL TREE usando K = 10, 
40, 70, 100 e 130
"""

k = 5 #são cinco valores de K
vizinhos = 10 #valor inicial de K

for elemento in range(k):

  knn = KNeighborsRegressor(n_neighbors = vizinhos, algorithm='ball_tree', metric='manhattan').fit(X_train, y_train)

  knn.fit(X_train, y_train)

  y_pred = knn.predict(X_test)

  print("\n")
  print("METRÍCAS DE AVALIAÇÃO PARA K = ", vizinhos)
  #R-Quadrado
  print()
  R2 = r2_score(y_test,y_pred) #Valor real e valor predito
  print("R-Quadrado:", R2)


  #R-Quadrado ajustado

  print("R-Quadrado ajustado", adjusted_r2(y_test,y_pred,X_train))


  MSE = mean_squared_error(y_test,y_pred)
  print("Erro Quadrático Médio:", MSE)

  MAE = mean_absolute_error(y_test,y_pred)
  print("Erro Absoluto Médio:", MAE)

  vizinhos += 30

"""Aplicação do KNN com a metríca de similaridade KD TREE usando K = 10, 40, 70, 100 e 130"""

k = 5 #são cinco valores de K
vizinhos = 10 #valor inicial de K

for elemento in range(k):

  knn = KNeighborsRegressor(n_neighbors = vizinhos, algorithm='kd_tree', metric='chebyshev').fit(X_train, y_train)

  knn.fit(X_train, y_train)

  y_pred = knn.predict(X_test)

  print("\n")
  print("METRÍCAS DE AVALIAÇÃO PARA K = ", vizinhos)
  #R-Quadrado
  print()
  R2 = r2_score(y_test,y_pred) #Valor real e valor predito
  print("R-Quadrado:", R2)


  #R-Quadrado ajustado

  print("R-Quadrado ajustado", adjusted_r2(y_test,y_pred,X_train))


  MSE = mean_squared_error(y_test,y_pred)
  print("Erro Quadrático Médio:", MSE)

  MAE = mean_absolute_error(y_test,y_pred)
  print("Erro Absoluto Médio:", MAE)

  vizinhos += 30