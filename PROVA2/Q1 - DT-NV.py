# -*- coding: utf-8 -*-
"""Questão 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bnxSmPvala1gooNes2C3dHSeCtpfvVQj

### **IMPORTAÇÃO DAS BIBLIOTECAS E LEITURA DO DATASET**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sn
import numpy as np
import scipy.stats
import matplotlib.pyplot as plt
from scipy.stats import norm
from sklearn.tree import plot_tree
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.model_selection import train_test_split
from sklearn import metrics 
from mlxtend.plotting import plot_decision_regions
from sklearn.utils import shuffle
from sklearn.metrics import roc_auc_score, average_precision_score
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif, mutual_info_classif
from sklearn.metrics import confusion_matrix
from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB
from sklearn.metrics import classification_report

# %matplotlib inline
# %pylab inline
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
plt.style.use('ggplot')


#Leitura da base de dados
data = pd.read_csv("Churn_Modelling.csv")
print(data)

"""### **PRÉ-PROCESSAMENTO DE DADOS**

Inicialmente foi necessário retirar alguns atributos que não colaboram para tomada de decisão dos algoritmos executados posteriomente. Outros atributos apresentaram-se como redundante e foram retirados. Após isso, as variaiveis categoricas (Gender e Geography) foram tratadas a partir da transformação dos valores nominais em numéricos. Por fim, realizou-se uma reescala dos dados uma vez que os atributos "EstimatedSalary", "Balance" e "CreditScore" possuem uma escala muito diferente dos demais atributos e isso, por consequência, ocasiona uma influência maior no resultado.
"""

#Excluir atributos
new_data = data.drop(['RowNumber', 'Surname', 'CustomerId'], axis=1) #Excluir os atributos

#Transformação de Variáveis Categóricas
labelencoder = LabelEncoder()
new_data.iloc[:, 1] = labelencoder.fit_transform(new_data.iloc[:, 1])
new_data.iloc[:, 2] = labelencoder.fit_transform(new_data.iloc[:, 2])
print(new_data)

#Normalização
normalized_geral = MinMaxScaler().fit_transform(new_data)
new_data_2 = pd.DataFrame(normalized_geral, columns=['CreditScore','Geography','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','Exited']) #Adicionar rotulos


#Dataset após o pré-processamento dos dados
print(new_data_2)

"""Para criação de uma nova variavel, optou-se por utilizar a Análise de Componentes Principais (PCA) a fim de gerar arranjos que melhor representação a distribuição dos dados e, consequentemente, possui impacto significativo dentre os atributos para identificar o target durante a etapa de teste do dataset. 

"""

#PCA
array_x = np.array(new_data_2.drop('Exited',1))
array_y = np.array(new_data_2['Exited'])

pca = PCA(n_components=1)
pca.fit(array_x)
x_1 = pca.transform(array_x)

data_x = np.concatenate((array_x, x_1), axis=1)
x = pd.DataFrame(data_x, columns=['CreditScore','Geography','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','PC1']) #Adicionar rotulos

print(x)
y = pd.DataFrame(array_y, columns=['Exited'])
print(y)

data_f = np.concatenate((x, y), axis=1)
data_final = pd.DataFrame(data_f, columns=['CreditScore','Geography','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','PC1','Exited']) #Adicionar rotulos
print(data_final)
#Aqui X e Y

"""### **ANÁLISE EXPLORATORIA DOS DADOS**

A princípio, foi gerado um quadro com estatisticas descritivas do modelo contendo a média dos valores das colunas, divisão da amostra de dados em ordem crescente (percentis), além do minimo e máximo desses valores. Esse quadro tem por intuito exibir uma visão numérica mais geral do modelo.
"""

data_final.describe()

"""Posteriomente, buscou-se realizar uma análise de correlação que toma como base o coeficiente de Pearson para medir o grau de correlação entre duas variáveis. Esse coeficiente irá assumir valores entre -1 e 1, no qual valores próximos as extremidades demonstram forte correlação e valores distantes (próximos a zero) possuem fraca correlação. Tomando como base que valores acima de de 0.7 possuem uma correlação significativa, fica evidenciado que a maioria das features possui pouca ou nenhuma relação com as outras. """

correlation = x.corr()
correlation

# Plot da matriz de correlação
try:
   plot = sn.heatmap(correlation, annot = True, fmt=".1f", linewidths=.6)
   plot
except ValueError:  
    pass

"""Nesse momento, é exibido um gráfico horizontal em barra que relaciona se o cliente é um membro ativo no banco com os dados dos clientes que fecharam a conta. Esse gráfico evidência que aproximadamente 35% dos membros **não ativos**, por algum motivo, ainda não realizaram o fechamento da conta. Além disso, aproximadamente 51% dos clientes são membros **ativos**, e apenas 14% desse grupo decidiram deixar o banco, mesmo com a realização de atividades recorrentes"""

#Comparação de ser membro ativo vs sair do banco
dados_1 = data_final.groupby(u'IsActiveMember')['Exited'].value_counts()
dados_1.plot.barh()

"""Foi aplicado também uma distruibição normal dos dados que fornece as probabilidades de ocorrência de diferentes resultados possíveis na base de dados. Nesse caso, buscou-se verificar a relação entre o fechamento da conta e a idade do cliente. Percebeu-se que há uma frequência maior dos dados entre as idades de 34-38 anos, atingindo o pico nos clientes com idade de 35 anos. Em contrapartidade, clientes com idade superior a 78 anos possuem baixo indice de encerramento de conta."""

close = data_final[data_final['Exited'] == 0]
open =  data_final[data_final['Exited'] == 1]

#Idade conta fechada
ageClose = close.groupby(u'Age')['Exited'].value_counts()

#Idade conta aberta
ageOpen = open.groupby(u'Age')['Exited'].value_counts()

pdf = scipy.stats.norm.pdf(ageClose, np.mean(ageClose), np.std(ageClose))
plt.plot(ageClose, pdf)

plt.legend(('Conta fechada', ''))
plt.show()

"""Utilizou-se a função SelectKBest para definir quais atributos são mais relevantes para tomada de decisão."""

f_classif = SelectKBest(score_func=f_classif, k=4)
fit = f_classif.fit(x,y)
features = fit.transform(x)

cols2 = fit.get_support(indices=True)
data_final.iloc[:,cols2]

"""###**ÁRVORE DE DECISÃO**

A árvore de decisão baseia-se no conceito de divisão dos dados em grupos homogêneos em que a partir do conjunto de dados é feito uma divisão e cada divisão representa um nó da árvore. A proposta desse algoritmo é encontrar a feature que gera a melhor divisão dos dados. É importante mencionar que nem todos os atributos foram utilizados para a criação da árvore de decisão. A ideia é encontrar o maior valor de predict durante os testes. Assim, as features foram, sucessivamente, sendo adicionadas de acordo com sua relevancia escolhida pela função SelectKBest.

Optou-se por variar os hiperparametros com a finilidade de gerar resultados diferentes e, posteriomente, comparar-los. Nesse primeiro momento, foi usado a métrica Índice Gini para definição do melhor atributo, com número minimo de amostrar para divisão de 24, e no nível da folha de 1. Além disso, a profundidade máxima da árvore é 3. **Random_state fixado em 42.**

**1) Parametros  = [3, 24, 5, 1, 'gini']**
"""

cols = ['IsActiveMember','Age','Balance', 'CreditScore', 'Exited']
simple_df = data_final[cols]
simple_df.head(2)

tree_y = simple_df['Exited']
tree_x = simple_df.loc[:, 'IsActiveMember':'CreditScore']

Xtrain, Xval, y_train, y_val = train_test_split(tree_x, tree_y, test_size=0.5, random_state=42)
Xtrain.shape, Xval.shape, y_train.shape, y_val.shape


#Parametros do modelos
max_depth = 3
min_samples_split = 24
min_samples_leaf = 5
max_features = 1
criterion = 'gini'

#Modelo
model_dtree = DecisionTreeClassifier(max_depth = max_depth,
                              min_samples_split = min_samples_split,
                              min_samples_leaf = min_samples_leaf,
                              max_features = max_features,
                              criterion = criterion,
                              random_state = 42,
                              class_weight = 'balanced')

model_dtree.fit(Xtrain,y_train)

# Previsão
pred_dtree = model_dtree.predict(Xval)

print('SCORE ROC-AUC:', np.round(roc_auc_score(y_val, pred_dtree),4))
print('PRECISÃO MÉDIA:', np.round(average_precision_score(y_val, pred_dtree),4))
print('')
print("MATRIZ DE CONFUSÃO")
print(confusion_matrix(y_val, y_train))

#Acurácia, precisão e F1
targ = ['0', '1']
print(classification_report(y_val, y_train, target_names=targ))
print("\n")

"""Para compreender como o algoritmo está performando, será usado duas métricas de avalição Score ROC-AUC, Precisão média e Matriz de confusão. O ROC-AUC indica o quanto o algoritmo classificiar corretamente a saída baseada no cálculo da área sob a curva de característica da ROC. Nesse caso, apresentou um valor aproximado de 64% de classificações corretas em todas as classes. A precisão média define se o modelo consegue identificar corretamento as amostrar positivas sem marcá-las como negativas e está diretamente relacionada com a precisão e recall vistos na matriz de confusão. Na matriz de confusão temos um valor de verdadeiro positivo interessante (3171), mostrando que o algoritmo preveu corretamente em 63% dos casos. Entretamento, com a visualização do recall, vemos uma boa taxa para a clientes que não sairam do banco (Classe 0) e uma taxa péssima para identificar quem saiu (classe 1). Isso se reflete em outras metricas como precisão e f1-score.

**2) Parametro = [50, 28, 9, 1, 'entropy']**
"""

Xtrain, Xval, y_train, y_val = train_test_split(tree_x, tree_y, test_size=0.5, random_state=42)
Xtrain.shape, Xval.shape, y_train.shape, y_val.shape

#Parametros do modelos
max_depth = 50
min_samples_split = 28
min_samples_leaf = 9
max_features = 1
criterion = 'entropy'

#Modelo
model_dtree = DecisionTreeClassifier(max_depth = max_depth,
                              min_samples_split = min_samples_split,
                              min_samples_leaf = min_samples_leaf,
                              max_features = max_features,
                              criterion = criterion,
                              random_state = 42,
                              class_weight = 'balanced')



model_dtree.fit(Xtrain,y_train)


# Previsão
pred_dtree = model_dtree.predict(Xval)

print('SCORE ROC-AUC::', np.round(roc_auc_score(y_val, pred_dtree),4))
print('PRECISÃO MÉDIA:', np.round(average_precision_score(y_val, pred_dtree),4))
print('')
print("MATRIZ DE CONFUSÃO")
print(confusion_matrix(y_val, y_train))

#Acurácia, precisão e F1
targ = ['0', '1']
print(classification_report(y_val, y_train, target_names=targ))
print("\n")

"""Quando foi realizado a alteração dos hiperparametros, não ocorreu mudanças significativas em nenhuma métrica avaliativa, inclusive, a matriz de confusão permaneceu igual.

###**CLASSIFICADOR NAIVE BAYES**

O algoritmo Naive Bayes é um classificador probabilístico. É eficiente em classificação de modelos e amplamente utilizada na área da saúde. Comparando os resultados com o modelo de classificação anterior, temos uma melhoria significativa em relação ao valor de precisão na classificação da amostra na classe 1 (saiu do banco). As métricas de recall e f1-score também apresentaram melhorias.
"""

Xtrain1, Xval1, y_train1, y_val1 = train_test_split(x, y, test_size=0.5, random_state=42)

# Classificação - Naive Bayes

gnb = GaussianNB()
used_features =['CreditScore','Geography','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary', 'PC1']

gnb.fit(
    Xtrain1[used_features].values,
    y_train1["Exited"])

y_pred1 = gnb.predict(Xval1[used_features])

mean_exited=np.mean(y_train1["Exited"])
mean_not_exited=1-mean_exited
print("Exited = 1 : {:03.2f}%, Exited = 0 : {:03.2f}%"
      .format(100*mean_exited,100*mean_not_exited))



print("MATRIZ DE CONFUSÃO")
print(confusion_matrix(y_val1, y_train1))

#Acurácia, precisão e F1
targ = ['0', '1']
print(classification_report(y_val1, y_pred1, target_names=targ))
print("\n")